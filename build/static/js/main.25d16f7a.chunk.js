(this.webpackJsonptaxonomy=this.webpackJsonptaxonomy||[]).push([[0],{115:function(e,t,a){},125:function(e,t,a){},126:function(e,t,a){"use strict";a.r(t);var i,s,n=a(0),d=a.n(n),l=(a(111),a(7)),r=a.n(l),o=(a(115),a(16)),m=a(8),p=a(129),c=a(22),h=a(23),u=h.a.div(i||(i=Object(c.a)(["\n  display: flex;\n  flex-direction: column;\n"]))),g=h.a.div(s||(s=Object(c.a)(["\n  width: 460px;\n  overflow-wrap: break-word;\n"]))),v=a(2),b=function(e){var t=e.show,a=e.setShow,i=e.node;return Object(v.jsx)(p.a,{show:t,onHide:function(){return a(!1)},children:i&&Object(v.jsxs)(v.Fragment,{children:[Object(v.jsx)(p.a.Header,{children:Object(v.jsx)(p.a.Title,{children:Object(v.jsx)(g,{children:i.name})})}),Object(v.jsx)(p.a.Body,{children:Object(v.jsxs)(u,{children:[Object(v.jsxs)("h6",{children:["ID ",i.id," \u2606 ",i.pipeline]}),Object(v.jsxs)("h6",{children:["Origin: ",i.origin]}),Object(v.jsx)("p",{children:i.description}),Object(v.jsx)("h6",{children:"DOIS"}),i.dois&&i.dois.map((function(e,t){return Object(v.jsx)("li",{children:e},t)}))]})})]})})},y=1200,f=10,z=10,w=-30,x=[w,-f,y,28],j=function(e,t){e.each((function(){for(var e,a=m.c(this),i=a.text().split(/\s+/).reverse(),s=[],n=0,d=a.attr("x"),l=a.attr("y"),r=a.text(null).append("tspan").attr("x",d).attr("y",l);e=i.pop();)s.push(e),r.text(s.join(" ")),r.node().getComputedTextLength()>t&&(s.pop(),r.text(s.join(" ")),s=[e],r=a.append("tspan").attr("x",d).attr("y",10*++n+l).text(e))}))},O=function(e){var t,a=0;for(t=0;t<e.length;t++)a=e.charCodeAt(t)+((a<<4)-a);var i="#";for(t=0;t<3;t++){i+=("00"+(a>>4*t&255).toString(26)).substr(-2)}return i},S=function(e,t){3===(e=e.replace(/^\s*#|\s*$/g,"")).length&&(e=e.replace(/(.)/g,"$1$1"));var a=parseInt(e.substr(0,2),16),i=parseInt(e.substr(2,2),16),s=parseInt(e.substr(4,2),16);return"#"+(0|256+a+(256-a)*t/100).toString(16).substr(1)+(0|256+i+(256-i)*t/100).toString(16).substr(1)+(0|256+s+(256-s)*t/100).toString(16).substr(1)},k=function(e){var t=e.data,a=d.a.useState(!1),i=Object(o.a)(a,2),s=i[0],n=i[1],l=d.a.useState(),r=Object(o.a)(l,2),p=r[0],c=r[1],h=d.a.useState(x),u=Object(o.a)(h,2),g=u[0],k=u[1],I=function(e,t){var a=d.a.useRef();return d.a.useEffect((function(){return e(m.c(a.current)),function(){}}),t),a}((function(e){var a=m.d().nodeSize([28,300]),i=m.a(t),s=m.b().x((function(e){return e.y})).y((function(e){return e.x}));i.x0=300,i.y0=0,i.descendants().forEach((function(e,t){e.id=t,e._children=e.children,e.depth>1&&(e.children=null)}));var d=e.append("g").attr("fill","none").attr("stroke","black").attr("stroke-opacity",.5).attr("stroke-width",1.5),l=e.append("g").attr("cursor","pointer").attr("pointer-events","all");!function t(r){var o=i.descendants().reverse(),m=i.links();a(i);var p=i,h=i;i.eachBefore((function(e){e.x<p.x&&(p=e),e.x>h.x&&(h=e)}));var u=h.x-p.x+f+z,g=e.transition().duration(250).attr("viewBox",[w,p.x-f,y,u]).tween("resize",window.ResizeObserver?null:function(){return function(){return e.dispatch("toggle")}}),v=l.selectAll("g").data(o,(function(e){return e.id})),b=v.enter().append("g").attr("transform",(function(e){return"translate(".concat(r.y0,",").concat(r.x0,")")})).attr("fill-opacity",0).attr("stroke-opacity",0).on("click",(function(a,i){0!==i.depth&&(i.children=i.children?null:i._children,t(i),function(t){var a=e.attr("viewBox").split(",");3===t.data.level&&(n(!0),k([Number(a[0]),Number(a[1]),Number(a[2]),Number(a[3])]),c(t.data))}(i))}));b.append("rect").attr("width",20).attr("height",15).attr("rx",5).attr("ry",5).attr("y",-10).attr("fill",(function(e){return function(e){if("Start"===e.data.name)return"#262626";if(e._children||3===e.data.level){var t=e.parent,a=t.parent,i=null!==a?"Start"===a.data.name?t.data.name:a.data.name:"Start"===t.data.name?e.data.name:t.data.name,s=O(i);return 1===e.data.level?S(s,20):2===e.data.level?S(s,40):3===e.data.level?S(s,60):"gray"}return"gray"}(e)})),b.append("text").attr("x",(function(e){return-2})).attr("text-anchor",(function(e){return"end"})).style("font-size","12px").text((function(e){return e.data.name})).call(j,200).clone(!0).lower().attr("stroke-linejoin","round").attr("stroke-width",2).attr("stroke","white"),v.merge(b).transition(g).attr("transform",(function(e){return"translate(".concat(e.y,",").concat(e.x,")")})).attr("fill-opacity",1).attr("stroke-opacity",1),v.exit().transition(g).remove().attr("transform",(function(e){return"translate(".concat(r.y,",").concat(r.x,")")})).attr("fill-opacity",0).attr("stroke-opacity",0);var x=d.selectAll("path").data(m,(function(e){return e.target.id})),I=x.enter().append("path").attr("d",(function(e){var t={x:r.x0,y:r.y0-30};return s({source:t,target:t})}));x.merge(I).transition(g).attr("d",s),x.exit().transition(g).remove().attr("d",(function(e){var t={x:r.x,y:r.y};return s({source:t,target:t})})),i.eachBefore((function(e){e.x0=e.x,e.y0=e.y}))}(i)}),[t.length]);return Object(v.jsxs)(v.Fragment,{children:[Object(v.jsx)(b,{show:s,node:p,setShow:n}),Object(v.jsx)("div",{style:{height:"100%",width:y},children:Object(v.jsx)("svg",{ref:I,viewBox:[g],style:{height:1400,width:"100%",userSelect:"none"}})})]})},I=a(38);a(125);var A=function(){return Object(v.jsx)("div",{className:"App",children:Object(v.jsx)(k,{data:I})})},B=function(e){e&&e instanceof Function&&a.e(3).then(a.bind(null,130)).then((function(t){var a=t.getCLS,i=t.getFID,s=t.getFCP,n=t.getLCP,d=t.getTTFB;a(e),i(e),s(e),n(e),d(e)}))};r.a.render(Object(v.jsx)(d.a.StrictMode,{children:Object(v.jsx)(A,{})}),document.getElementById("root")),B()},38:function(e){e.exports=JSON.parse('{"name":"Start","children":[{"name":"Requirement definition","children":[{"name":"Retraining model","children":[{"name":"data to avoid overfitting","id":300,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":200,"level":2},{"name":"External services","children":[{"name":"randomly randomly to balance data","id":301,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":201,"level":2},{"name":"Metric selection","children":[{"name":"randomly randomly to balance data2","id":302,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":202,"level":2},{"name":"Probabilistic model","children":[{"name":"only on training","id":303,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":203,"level":2}],"id":100,"level":1},{"name":"EDA","children":[{"name":"Define types of features and  dependencies between them","children":[{"name":"training imputation on validation and test datasets","id":304,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"noisy data","id":305,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":204,"level":2},{"name":"Detect trends, errors  and relations in data","children":[{"name":"depedant and independant variables","id":306,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"right type for each feature","id":307,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"order of a feature if required when clustering is applied","id":308,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"Categorical multiple binary","id":309,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"datetime features with sine/cosine facets","id":310,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":205,"level":2}],"id":101,"level":1},{"name":"DATA","children":[{"name":"Improve performance","children":[{"name":"datetime features with frequencies or general features","id":311,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":206,"level":2},{"name":"Prevent computation of  biased metrics and avoid overfitting","children":[{"name":"image 2 2d array","id":312,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"dataset for regression when data is dependable on categorical data","id":313,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":207,"level":2},{"name":"Dataset construction","children":[{"name":"datetime into four features","id":314,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"image crop object of interest to detect","id":315,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"image 2 characters","id":316,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"image 2 characters2","id":317,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"data based on algorithms","id":318,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"data relu","id":319,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"based on algorithm and data","id":320,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":208,"level":2},{"name":"Ensure minimum size and how to measure the size","children":[{"name":"when model sensitive magnitude","id":321,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"when using SVM","id":322,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"with training statistics","id":323,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":209,"level":2}],"id":102,"level":1},{"name":"Labeling","children":[{"name":"Scalability","children":[{"name":"data","id":324,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":210,"level":2},{"name":"Parametrize","children":[{"name":"all datasets with training statistics","id":325,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":211,"level":2}],"id":103,"level":1},{"name":"Feature selection","children":[{"name":"Consider existing techniques and their assumptions","children":[{"name":"directional statistics to handle geo data","id":326,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"average word embeding when using set invariant to permutation","id":327,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"geodesic distance to predict geo data","id":328,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"manifold learning methods for unsupervised feature engineering","id":329,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"dummy data when having categorical data in regression","id":330,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"cyclical features to encode date/time","id":331,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"oversample after samplingdata","id":332,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"imputation techiques when missing data","id":333,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"existing routines for data cleaning","id":334,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"using hashing and salt","id":335,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"invariant algorithms when having mixed data","id":336,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"data based on algorithms","id":337,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":212,"level":2},{"name":"General ","children":[{"name":"data","id":338,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"all numeric features","id":339,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":213,"level":2}],"id":104,"level":1},{"name":"Wrangling","children":[{"name":"Transform  numerical features","children":[{"name":"all numeric features2","id":340,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"geoloccation data to deduce information","id":341,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"a superset vocabulary","id":342,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"features only on train data","id":343,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"different selection techniques","id":344,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":214,"level":2},{"name":"Transform non numerical data","children":[{"name":"dimensionality reduction","id":345,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"pca assumptions hold","id":346,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":215,"level":2},{"name":"Transform misellaneous data type","children":[{"name":"Backward or forward selection independently any classifier","id":347,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"dimensionality reduction technique","id":348,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":216,"level":2},{"name":"Augment dataset","children":[{"name":"elastic net when high collinearity","id":349,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":217,"level":2},{"name":"Encode non numerical data","children":[{"name":"lasso regularization","id":350,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"mutual information","id":351,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"regularization in algorithms","id":352,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"variable important index given by random forest","id":353,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":218,"level":2},{"name":"Encode misellaneous","children":[{"name":"latent variables","id":354,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"lasso ridge or glmnet when doing multiple regression","id":355,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":219,"level":2},{"name":"Encode numerical data","children":[{"name":"ROC for evaluating hypotesis for specific feature","id":356,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":220,"level":2},{"name":"Impute missing data","children":[{"name":"p value greater than 0.5 in logistic regression","id":357,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":221,"level":2},{"name":"Balance data","children":[{"name":"multivariate over univariate","id":358,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"multivariate over univariate2","id":359,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"multivariate over univariate3","id":360,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":222,"level":2},{"name":"Eliminate noisy data","children":[{"name":"data errors","id":361,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":223,"level":2},{"name":"Prepare dataset","children":[{"name":"time trends","id":362,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":224,"level":2}],"id":105,"level":1},{"name":"Implementation","children":[{"name":"Reproducibility/replicability","children":[{"name":"missing values","id":363,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"missing values2","id":364,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"missing values3","id":365,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":225,"level":2},{"name":"Documentation/traceability","children":[{"name":"bayesian optimization","id":366,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"compare training test performance","id":367,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":226,"level":2},{"name":"Consistency/Integrity","children":[{"name":"cross validation","id":368,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":227,"level":2},{"name":"Resources usage","children":[{"name":"nested cross validation","id":369,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"model selection performed separately in each trial","id":370,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"by using multiple randomised partitionings of the available data","id":371,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"use hold out if crossvalidation is for verification","id":372,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"introduce unwanted confounding between origins and seasonality","id":373,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":228,"level":2}],"id":106,"level":1},{"name":"Validation","children":[{"name":"Things to consider when evaluating a model","children":[{"name":"performance over a wide range of datasets","id":374,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"algorithms time vs accuracy","id":375,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"model in test set after cross-validation for hyperparameter tuning","id":376,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"with nested-crossvalidation when desirable lower random uncertainty","id":377,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"dataset samples time vs accuracy","id":378,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"hyperparameter in valdation set","id":379,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"classifiers independently when using ensemble","id":380,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"learning curves","id":381,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"metrics based on goal","id":382,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"model based on test set","id":383,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"derivates of cost function when objectives functions slow or do not converge","id":384,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"metrics at the end of epoch","id":385,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"best hyperparameters on test set","id":386,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"vocabulary from training set when using crossvalidation","id":387,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"cost function","id":388,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"crossvalidation instead training test split","id":389,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"crossvalidation when data insuficient to split in training validation testing","id":390,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"nested-crossvalidation instead training test split","id":391,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":229,"level":2},{"name":"Hyper parameter tuning","children":[{"name":"random seed to assure reproducibility and fair comparison when training deep neural network","id":392,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"repeated cross validation with different seed to avoid impact of fixed seed","id":393,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"several runs of cross validation or bootstrap","id":394,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"single cross validation and test with several seed to avoid seed impact","id":395,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":230,"level":2},{"name":"Unit testing","children":[{"name":"use adversarial inputs for testing","id":396,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":231,"level":2},{"name":"Avoid overfitting","children":[{"name":"use annotated data for unit testing","id":397,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"when using rolling origin on large dataset","id":398,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"membership new data to training set","id":399,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"probabilistic model optimization from probability threshold selection","id":400,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"model is not biased when building superset vocabulary","id":401,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"model is not biased when building superset vocabulary2","id":402,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":232,"level":2}],"id":107,"level":1},{"name":"Deployment","children":[{"name":"Avoid overfitting","children":[{"name":"model is not biased when building superset vocabulary3","id":403,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"retrain with new observation","id":404,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":233,"level":2}],"id":108,"level":1},{"name":"Training","children":[{"name":"Select learning rate","children":[{"name":"retrain with new observation2","id":405,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"retrain with new observation3","id":406,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":234,"level":2},{"name":"Retraining models","children":[{"name":"multiple humans","id":407,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"tool that fixed aspect ratio for object detection","id":408,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"tool that fixed aspect ratio for object detection3","id":409,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"efficiency of io","id":410,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":235,"level":2},{"name":"Convergence","children":[{"name":"training to optimize time","id":411,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"pipelines","id":412,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"resource aware implementations","id":413,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"separate files","id":414,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"pipelines to enable reproducibility data preprocessing","id":415,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":236,"level":2},{"name":"Improve performance","children":[{"name":"params","id":416,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"},{"name":"data deletion in pipeline","id":417,"level":3,"description":"transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)","pipeline":"pipeline"}],"id":237,"level":2}],"id":109,"level":1}]}')}},[[126,1,2]]]);
//# sourceMappingURL=main.25d16f7a.chunk.js.map